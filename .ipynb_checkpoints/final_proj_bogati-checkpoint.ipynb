{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owj7-b6cq00k"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('/content/drive/MyDrive/drl_proj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzvWZklVwgXO",
    "outputId": "c9fa8264-37de-465f-e5d0-8555803c4000"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from opencv-python) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyheif in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (0.7.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from pyheif) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from cffi>=1.0.0->pyheif) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install --use-pep517 pyheif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (24.0)\n",
      "Requirement already satisfied: tensorflow in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.48.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.35.1)\n",
      "Requirement already satisfied: rich in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: keras in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (3.3.2)\n",
      "Requirement already satisfied: absl-py in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from keras) (1.23.5)\n",
      "Requirement already satisfied: rich in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from keras) (13.3.5)\n",
      "Requirement already satisfied: namex in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from optree->keras) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/saranshbogati/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade tensorflow\n",
    "!pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dlib\n",
      "  Using cached dlib-19.24.4.tar.gz (3.3 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: dlib\n",
      "  Building wheel for dlib (pyproject.toml) ... \u001b[?25l\\"
     ]
    }
   ],
   "source": [
    "!pip install --use-pep517 dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bKayXhnbuF3H"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Flatten, Dense\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdlib\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image  \u001b[38;5;66;03m# PIL is often used indirectly through other imports but import explicitly if needed\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dlib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import dlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image  # PIL is often used indirectly through other imports but import explicitly if needed\n",
    "import pyheif  # Importing the HEIC handling library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pUbzPdK3y_VX",
    "outputId": "46c6d62e-deca-4521-8cb8-8bf54f4a8ff9"
   },
   "outputs": [],
   "source": [
    "# Defining image dimensions\n",
    "img_width, img_height = 100, 100\n",
    "\n",
    "# Loading and preprocessing images for emotion detection\n",
    "X_emotion = []\n",
    "y_emotion = []\n",
    "\n",
    "emotions = ['happy', 'sad', 'neutral']\n",
    "\n",
    "def get_img(full_path):\n",
    "  if full_path.lower().endswith('.heic'):\n",
    "      img = read_heic_image(full_path)\n",
    "      img = img.resize((img_width, img_height))\n",
    "  else:\n",
    "      img = Image.open(full_path)\n",
    "      img = img.resize((img_width, img_height))\n",
    "\n",
    "  return img\n",
    "\n",
    "def convert_grayscale_to_rgb(image):\n",
    "    \"\"\"\n",
    "    Convert a grayscale image to RGB.\n",
    "\n",
    "    Args:\n",
    "    image: A grayscale image.\n",
    "\n",
    "    Returns:\n",
    "    The RGB version of the input image.\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "for emotion in emotions:\n",
    "    folder = f'{emotion}'\n",
    "    label = emotions.index(emotion)\n",
    "    for filename in os.listdir(folder):\n",
    "      filepath  = os.path.join(folder, filename)\n",
    "      print('Processing file', filepath)\n",
    "      img = get_img(filepath)\n",
    "      img_array = img_to_array(img)\n",
    "      X_emotion.append(img_array)\n",
    "      y_emotion.append(label)\n",
    "\n",
    "X_emotion = np.array(X_emotion)\n",
    "y_emotion = np.array(y_emotion)\n",
    "\n",
    "# Splitting the data into training and validation sets for emotion detection\n",
    "X_train_emotion, X_val_emotion, y_train_emotion, y_val_emotion = train_test_split(\n",
    "    X_emotion, y_emotion, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0UIzrBce023V",
    "outputId": "050eba8f-cde4-476c-fa3d-7a168ebaece4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 869
    },
    "id": "56OSgAF9tbH5",
    "outputId": "5a569225-ea58-4071-8058-f828c99982d2"
   },
   "outputs": [],
   "source": [
    "def read_heic_image(file_path):\n",
    "    heif_file = pyheif.read(file_path)\n",
    "    image = Image.frombytes(\n",
    "        heif_file.mode,\n",
    "        heif_file.size,\n",
    "        heif_file.data,\n",
    "        \"raw\",\n",
    "        heif_file.mode,\n",
    "        heif_file.stride,\n",
    "    )\n",
    "    return image\n",
    "\n",
    "def plot_emotion_history(emotion_history):\n",
    "  # Plotting training history\n",
    "  plt.figure(figsize=(10, 5))\n",
    "  plt.plot(emotion_history.history['accuracy'], label='accuracy')\n",
    "  plt.plot(emotion_history.history['val_accuracy'], label='val_accuracy')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.ylim([0, 1])\n",
    "  plt.legend(loc='lower right')\n",
    "  plt.title('Emotion Detection Model Accuracy')\n",
    "  plt.show()\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "      # Defining CNN model architecture for emotion detection\n",
    "      emotion_model = Sequential([\n",
    "          Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),  # RGB images\n",
    "          MaxPooling2D((2, 2)),\n",
    "          Conv2D(64, (3, 3), activation='relu'),\n",
    "          MaxPooling2D((2, 2)),\n",
    "          Conv2D(128, (3, 3), activation='relu'),\n",
    "          MaxPooling2D((2, 2)),\n",
    "          Flatten(),\n",
    "          Dense(128, activation='relu'),\n",
    "          Dense(len(emotions), activation='softmax')  # Multiclass classification for emotions\n",
    "      ])\n",
    "\n",
    "      # Compiling the emotion detection model\n",
    "      emotion_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "      # Training the emotion detection model\n",
    "      emotion_history = emotion_model.fit(\n",
    "          X_train_emotion, y_train_emotion, epochs=10, batch_size=32, validation_data=(X_val_emotion, y_val_emotion)\n",
    "      )\n",
    "\n",
    "      # Evaluating the emotion detection model\n",
    "      emotion_loss, emotion_accuracy = emotion_model.evaluate(X_val_emotion, y_val_emotion)\n",
    "      print(f'Emotion Detection - Validation Loss: {emotion_loss}, Validation Accuracy: {emotion_accuracy}')\n",
    "\n",
    "      # Saving the emotion detection model\n",
    "      emotion_model.save('emotion_detection_model_updated.keras')\n",
    "\n",
    "      # plot\n",
    "      plot_emotion_history(emotion_history)\n",
    "\n",
    "      # Loading pre-trained face recognition model\n",
    "      detector = dlib.get_frontal_face_detector()\n",
    "      predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "      # Loading images for Saransh and Nished\n",
    "      saransh_images_folder = \"saransh_images\"\n",
    "      nished_images_folder = \"nished_images\"\n",
    "\n",
    "      saransh_images = [os.path.join(saransh_images_folder, filename) for filename in os.listdir(saransh_images_folder)]\n",
    "      nished_images = [os.path.join(nished_images_folder, filename) for filename in os.listdir(nished_images_folder)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFzv80LZ2ar7"
   },
   "outputs": [],
   "source": [
    "\n",
    "def recognize_faces_and_detect_emotions():\n",
    "    \"\"\"\n",
    "    Recognize faces and detect emotions using the webcam.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detecting faces\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = detector(gray)\n",
    "\n",
    "        for face in faces:\n",
    "            x1, y1, x2, y2 = face.left(), face.top(), face.right(), face.bottom()\n",
    "\n",
    "            name = None  # Initializing name variable\n",
    "\n",
    "            # Recognizing Saransh and Nished's faces\n",
    "            if is_saransh(gray[y1:y2, x1:x2]):\n",
    "                name = 'Saransh'\n",
    "                age = 26\n",
    "                gender = 'Male'\n",
    "            elif is_nished(gray[y1:y2, x1:x2]):\n",
    "                name = 'Nished'\n",
    "                age = 27\n",
    "                gender = 'Male'\n",
    "\n",
    "            # Checking if name is assigned a value\n",
    "            if name is not None:\n",
    "                # Generating the voice message\n",
    "                voice_message = f\"Hi {name}\"\n",
    "\n",
    "                # Drawing text annotations on the video frame\n",
    "                cv2.putText(frame, f'Name: {name}', (x1, y1 - 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(frame, f'Age: {age}', (x1, y1 - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(frame, f'Gender: {gender}', (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "            # Detecting eyes (if needed) and other processing continues...\n",
    "\n",
    "            # Extracting face ROI for emotion detection\n",
    "            face_roi = gray[y1:y2, x1:x2]\n",
    "            face_roi = cv2.resize(face_roi, (img_width, img_height))\n",
    "            face_roi_processed = preprocess_image(face_roi)\n",
    "            emotion_prediction = emotion_model.predict(face_roi_processed)\n",
    "            emotion_label = emotions[np.argmax(emotion_prediction)]\n",
    "\n",
    "            # Displaying the predicted emotion on the video frame\n",
    "            cv2.putText(frame, f'Emotion: {emotion_label}', (x1, y1 - 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "            # Drawing rectangle around the face\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            # Detecting face landmarks\n",
    "            landmarks = predictor(gray, face)\n",
    "            for n in range(0, 68):\n",
    "                x = landmarks.part(n).x\n",
    "                y = landmarks.part(n).y\n",
    "                cv2.circle(frame, (x, y), 1, (255, 0, 0), -1)\n",
    "\n",
    "        # Displaying the frame\n",
    "        cv2.imshow('Face Recognition and Emotion Detection', frame)\n",
    "\n",
    "        # Checking if the user pressed 'q' to quit the program\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Releasing the video capture object and closing all OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "# Function to compute histogram similarity between two images\n",
    "def histogram_similarity(image1, image2):\n",
    "    hist1 = cv2.calcHist([image1], [0], None, [256], [0, 256])\n",
    "    hist2 = cv2.calcHist([image2], [0], None, [256], [0, 256])\n",
    "    similarity = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
    "    return similarity\n",
    "\n",
    "# Function to recognize Nished's face\n",
    "def is_nished(face_roi):\n",
    "    nished_threshold = 0.1  # Adjust the threshold as needed\n",
    "    for nished_image_path in nished_images:\n",
    "        nished_image = cv2.imread(nished_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        similarity = histogram_similarity(face_roi, nished_image)\n",
    "        if similarity > nished_threshold:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Function to recognize Saransh's face\n",
    "def is_saransh(face_roi):\n",
    "    saransh_threshold = 0.8  # Adjust the threshold as needed\n",
    "    for saransh_image_path in saransh_images:\n",
    "        saransh_image = cv2.imread(saransh_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        similarity = histogram_similarity(face_roi, saransh_image)\n",
    "        if similarity > saransh_threshold:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Function to preprocess image for emotion model prediction\n",
    "def preprocess_image(img):\n",
    "    if len(img.shape) == 2:  # Checking if image is grayscale\n",
    "        img = convert_grayscale_to_rgb(img)\n",
    "    img = cv2.resize(img, (img_width, img_height))  # Resizing to match model input size\n",
    "    img = img.astype('float32') / 255.0  # Normalizing pixel values\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFxd6nFSxSX4"
   },
   "outputs": [],
   "source": [
    "recognize_faces_and_detect_emotions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQBkaZ8P45TM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
